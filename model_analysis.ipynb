{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01537d7f-d11d-4a68-a954-368f6d3099f2",
   "metadata": {},
   "source": [
    "# Brain Tumor Classification using CNN\n",
    "**Author:** Samay Asubadin  \n",
    "**Degree:** Biomedical Engineering, Korea University  \n",
    "\n",
    "This notebook presents the exploratory analysis, visualization, and qualitative evaluation\n",
    "of a Convolutional Neural Network trained to classify brain MRI images into four categories:\n",
    "glioma, meningioma, pituitary tumor, and non-tumor.\n",
    "\n",
    "The core training and evaluation pipeline is implemented in `Brain_tumor_SamayAsubadin.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f568e7f-f73a-452f-b8e3-09936bc0ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9886526c-171d-4ee0-a145-a42cb764752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = os.getcwd()\n",
    "\n",
    "DATASET_DIR = os.path.join(PROJECT_ROOT, \"data\")\n",
    "TRAIN_DIR   = os.path.join(DATASET_DIR, \"Train\")\n",
    "TEST_DIR    = os.path.join(DATASET_DIR, \"Test\")\n",
    "\n",
    "MODEL_DIR  = os.path.join(PROJECT_ROOT, \"models\")\n",
    "MODEL_PATH = os.path.join(MODEL_DIR, \"brain_tumor_cnn_model.keras\")\n",
    "\n",
    "classes = ['glioma', 'meningioma', 'nontumor', 'pituitary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb456d-9596-4df6-9c62-bc259348a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in classes:\n",
    "    path = os.path.join(TRAIN_DIR, cls)\n",
    "    print(f\"{cls}: {len(os.listdir(path))} images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be069af-72d9-43e7-b8a3-559384440fa1",
   "metadata": {},
   "source": [
    "## Class Distribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6403f083-05f3-494b-9050-0b15ec801e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = [len(os.listdir(os.path.join(TRAIN_DIR, c))) for c in classes]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=classes, y=class_counts, palette='viridis', hue=class_counts, legend=False)\n",
    "plt.title(\"Training Set Class Distribution\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29bd322-ee01-4d45-a00e-eabbf8f37e12",
   "metadata": {},
   "source": [
    "## Visualizing Random Training Samples\n",
    "Ransom samples are visualized to qualitatively inspect image quality, contrast, and inter-class variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c70899-ceac-4db6-979a-5f28b84c32b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 4, figsize=(15, 10))\n",
    "fig.suptitle(\"Random Training Samples\", fontsize=18)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    cls = random.choice(classes)\n",
    "    img_name = random.choice(os.listdir(os.path.join(TRAIN_DIR, cls)))\n",
    "    img_path = os.path.join(TRAIN_DIR, cls, img_name)\n",
    "\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(cls)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b141e664-05b6-4094-9e3e-722449d786e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Train model\n",
    "model = load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9f7094-98a2-4d85-b1ee-5f61773ad0de",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6abb680-3d0e-4874-86e0-265095ef97d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=1,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "preds = model.predict(test_gen)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "y_true = test_gen.classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae4c5c-9d40-4e07-a60e-e9a4520e761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\",\n",
    "            xticklabels=classes,\n",
    "            yticklabels=classes,\n",
    "            annot_kws={\"size\": 8},\n",
    "            cmap=\"Blues\")\n",
    "\n",
    "plt.xlabel(\"Predicted Label\", fontsize=10)\n",
    "plt.ylabel(\"True Label\", fontsize=10)\n",
    "plt.title(\"Confusion Matrix\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc6d569-5096-40c6-ad6e-07bd2a2e19b1",
   "metadata": {},
   "source": [
    "## Predicted vs. Actual Image Classification\n",
    "This visualization highlights both correct and incorrect predictions,\n",
    "providing insight into common failure modes and class-specific ambiguity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4111bdad-1827-479a-8276-bef75c9b6152",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 4, figsize=(15, 10))\n",
    "fig.suptitle(\"Predicted vs Actual Labels\", fontsize=18)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    img_path = test_gen.filepaths[i]\n",
    "    true_label = classes[y_true[i]]\n",
    "    pred_label = classes[y_pred[i]]\n",
    "\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "\n",
    "    color = \"green\" if true_label == pred_label else \"red\"\n",
    "\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    ax.set_title(f\"Pred: {pred_label}\\nActual: {true_label}\", color=color)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3be4a22-3e79-478a-88f4-58e6fde0bc26",
   "metadata": {},
   "source": [
    "## Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6badb2-9707-4e51-8d25-c10d9ec1abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "HISTORY_PATH = \"models/training_history.npy\"\n",
    "history = np.load(HISTORY_PATH, allow_pickle=True).item()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['accuracy'], 'bo-', label='Train')\n",
    "plt.plot(history['val_accuracy'], 'ro-', label='Val')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['loss'], 'bo-', label='Train')\n",
    "plt.plot(history['val_loss'], 'ro-', label='Val')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeab699f-6d44-41eb-b5dd-f7804ab8bc7f",
   "metadata": {},
   "source": [
    "## Interpretation \n",
    "The training set exhibits a moderately balanced class distribution across the four categories, with nontumor images being slightly more prevalent than tumor classes. While this imbalance is not extreme, it likely contributes to the modelâ€™s stronger performance on the nontumor class, as reflected in both the confusion matrix and the classification metrics.\n",
    "\n",
    "Overall, the model achieves an accuracy of 88% on the test set, indicating effective learning of discriminative features from brain MRI images. Performance varies across classes. Pituitary tumors and nontumor cases are classified with the highest reliability, achieving recall values of 0.99 and 0.98, respectively. This suggests that these categories exhibit distinctive visual patterns that are well captured by the convolutional filters. In contrast, meningioma shows the weakest performance, with a recall of 0.68, indicating that a substantial number of meningioma cases are misclassified.The confusion matrix reveals that the most common errors occur between glioma and meningioma. This confusion is expected, as these tumor types often share overlapping morphological characteristics in MRI scans, such as similar intensity distributions and boundary textures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00e6f5c-6c9d-4b19-bb14-85a0c2fd2cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
